package com.cloud_ml_app_thesis.util;

import com.cloud_ml_app_thesis.entity.*;
import com.cloud_ml_app_thesis.entity.dataset.Dataset;
import com.cloud_ml_app_thesis.dto.request.train.TrainingStartRequest;
import com.cloud_ml_app_thesis.dto.response.*;
import com.cloud_ml_app_thesis.entity.model.Model;
import com.cloud_ml_app_thesis.entity.status.TrainingStatus;
import com.cloud_ml_app_thesis.enumeration.AlgorithmTypeEnum;
import com.cloud_ml_app_thesis.enumeration.DatasetFunctionalTypeEnum;
import com.cloud_ml_app_thesis.enumeration.status.TrainingStatusEnum;
import com.cloud_ml_app_thesis.repository.*;
import com.cloud_ml_app_thesis.repository.dataset.DatasetRepository;
import com.cloud_ml_app_thesis.repository.model.ModelRepository;
import com.cloud_ml_app_thesis.repository.status.TrainingStatusRepository;
import com.cloud_ml_app_thesis.service.DatasetService;
import com.cloud_ml_app_thesis.service.MinioService;
import jakarta.persistence.EntityNotFoundException;
import lombok.*;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Component;
import org.springframework.web.multipart.MultipartFile;
import weka.core.Instances;

import java.io.InputStream;
import java.time.ZonedDateTime;

@Component
@RequiredArgsConstructor
@Slf4j
public class TrainingHelper {

    private final TrainingRepository trainingRepository;
    private final ModelRepository modelRepository;

    private final AlgorithmConfigurationRepository algorithmConfigurationRepository;

    private final AlgorithmRepository algorithmRepository;

    private final DatasetRepository datasetRepository;

    private final DatasetConfigurationRepository datasetConfigurationRepository;

    private final DatasetService datasetService;

    private final MinioService minioService;

    private final TrainingStatusRepository trainingStatusRepository;

    public TrainingDataInput configureTrainingDataInputByTrainCase(TrainingStartRequest request, User user) throws Exception {
        log.info("ğŸ”§ Configuring training input for user: {}", user.getUsername());

        MultipartFile file = request.getFile();
        boolean hasFile = ValidationUtil.multipartFileExist(file);
        boolean hasDatasetId = ValidationUtil.stringExists(request.getDatasetId());
        boolean hasDatasetConfId = ValidationUtil.stringExists(request.getDatasetConfigurationId());
        boolean hasAlgorithmId = ValidationUtil.stringExists(request.getAlgorithmId());
        boolean hasAlgorithmConfId = ValidationUtil.stringExists(request.getAlgorithmConfigurationId());
        boolean hasBasicCols = ValidationUtil.stringExists(request.getBasicCharacteristicsColumns());
        boolean hasTargetCol = ValidationUtil.stringExists(request.getTargetClassColumn());
        boolean hasAlgorithmOpts = ValidationUtil.stringExists(request.getOptions());
        boolean hasTrainingId = ValidationUtil.stringExists(request.getTrainingId());
        boolean hasModelId = ValidationUtil.stringExists(request.getModelId());
        final boolean retrainMode = hasTrainingId || hasModelId; // âœ… NEW

        // ----- Conflicts (ÎºÏÎ±Ï„Î¬Ï‰ Ï„Î± Ï…Ï†Î¹ÏƒÏ„Î¬Î¼ÎµÎ½Î±, Î¼Îµ 2 Î¼Î¹ÎºÏÎ­Ï‚ Î±Î»Î»Î±Î³Î­Ï‚)
        if (hasTrainingId && hasModelId)
            return error("âŒ You can't train based on both a training and a model.");

        if (hasDatasetId && hasFile)
            return error("âŒ Provide either an uploaded dataset OR a new file, not both.");

        if (hasDatasetId && hasDatasetConfId)
            return error("âŒ Cannot use both datasetId and datasetConfigurationId.");

        if (hasDatasetConfId && hasBasicCols && hasTargetCol)
            return error("âŒ When using a datasetConfigurationId, omit basicCharacteristicsColumns and targetClassColumn.");

        if (hasAlgorithmId && hasAlgorithmConfId)
            return error("âŒ Cannot use both algorithmId and algorithmConfigurationId.");

        // ÎœÎ— Î¼Ï€Î»Î¿ÎºÎ¬ÏÎµÎ¹Ï‚ "full new training" ÏŒÏ„Î±Î½ ÎµÎ¯Î¼Î±ÏƒÏ„Îµ ÏƒÎµ fresh mode.
        if (retrainMode && hasAlgorithmConfId && hasDatasetConfId && hasTargetCol && hasBasicCols && hasAlgorithmOpts)
            return error("âŒ This looks like a full new training; for retraining omit dataset/algorithm re-definitions.");

        // ----- Upload Î½Î­Î¿Ï… Î±ÏÏ‡ÎµÎ¯Î¿Ï… (Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹)
        String datasetId;
        if (hasFile) {
            GenericResponse<Dataset> uploadResp = datasetService.uploadDataset(file, user, DatasetFunctionalTypeEnum.TRAIN);
            datasetId = uploadResp.getDataHeader().getId().toString();
            hasDatasetId = true;
            log.info("ğŸ“‚ File uploaded, datasetId = {}", datasetId);
        } else {
            datasetId = request.getDatasetId();
        }

        // ----- Î’ÏÎµÏ‚ base training Î±Î½ ÎµÎ¯Î¼Î±ÏƒÏ„Îµ ÏƒÎµ retrain mode
        Training retrainedFrom = null;
        if (hasTrainingId) {
            retrainedFrom = trainingRepository.findById(Integer.parseInt(request.getTrainingId()))
                    .orElseThrow(() -> new EntityNotFoundException("Training not found."));
            log.info("ğŸ” Re-training from trainingId={}", retrainedFrom.getId());
        } else if (hasModelId) {
            Model model = modelRepository.findById(Integer.parseInt(request.getModelId()))
                    .orElseThrow(() -> new EntityNotFoundException("Model not found."));
            retrainedFrom = trainingRepository.findByModel(model)
                    .orElseThrow(() -> new EntityNotFoundException("Training not found for model."));
            log.info("ğŸ” Re-training from modelId={}, trainingId={}", model.getId(), retrainedFrom.getId());
        }

        // ----- Resolve DatasetConfiguration + Instances (Î¼Îµ ÏƒÏ‰ÏƒÏ„ÏŒ fallback)
        Instances datasetInstances;
        DatasetConfiguration datasetConf;

        if (hasDatasetId) {
            // fresh Î® retrain Î¼Îµ Î½Î­Î¿ datasetId -> Ï†Ï„Î¹Î¬Î¾Îµ/ÎµÎ½Î·Î¼Î­ÏÏ‰ÏƒÎµ DatasetConfiguration
            Dataset dataset = datasetRepository.findById(Integer.parseInt(datasetId))
                    .orElseThrow(() -> new EntityNotFoundException("Dataset not found: id=" + datasetId));

            datasetConf = new DatasetConfiguration();
            datasetConf.setDataset(dataset);
            if (hasBasicCols) datasetConf.setBasicAttributesColumns(request.getBasicCharacteristicsColumns());
            if (hasTargetCol) datasetConf.setTargetColumn(request.getTargetClassColumn());
            datasetConf.setUploadDate(ZonedDateTime.now()); // âœ… ÎµÏ…Î¸Ï…Î³ÏÎ¬Î¼Î¼Î¹ÏƒÎ· Î¼Îµ Ï„Î¿ clustering branch
            datasetConf = datasetConfigurationRepository.save(datasetConf);

            // Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î±Ï€ÏŒ MinIO Î¼Î­ÏƒÏ‰ DatasetService (âœ… ÏŒÏ‡Î¹ Î±Ï€ÎµÏ…Î¸ÎµÎ¯Î±Ï‚ MinioService)
            datasetInstances = datasetService.loadTrainingInstances(datasetConf);

        } else if (hasDatasetConfId) {
            datasetConf = datasetConfigurationRepository.findById(Integer.parseInt(request.getDatasetConfigurationId()))
                    .orElseThrow(() -> new EntityNotFoundException("DatasetConfiguration not found."));

            // Î•Ï€Î¯Ï„ÏÎµÏˆÎµ overrides ÎœÎŸÎÎŸ Î±Î½ Î´ÏŒÎ¸Î·ÎºÎ±Î½ (Î±Î»Î»Î¹ÏÏ‚ ÎºÏÎ¬Ï„Î± Ï„Î¿ Î¯Î´Î¹Î¿)
            if (hasBasicCols) datasetConf.setBasicAttributesColumns(request.getBasicCharacteristicsColumns());
            if (hasTargetCol) datasetConf.setTargetColumn(request.getTargetClassColumn());
            datasetConf = datasetConfigurationRepository.save(datasetConf);

            datasetInstances = datasetService.loadTrainingInstances(datasetConf); // âœ…

        } else if (retrainMode) {
            // âœ… Fallback: Ï€Î¬ÏÎµ Ï„Î¿ Î Î¡ÎŸÎ—Î“ÎŸÎ¥ÎœÎ•ÎÎŸ DatasetConfiguration
            DatasetConfiguration baseConf = retrainedFrom.getDatasetConfiguration();
            if (baseConf == null)
                return error("âŒ Base training has no DatasetConfiguration.");

            // Î‘Î½ Î´ÎµÎ½ Î´Î¯Î½Î¿Î½Ï„Î±Î¹ overrides, Î§Î¡Î—Î£Î™ÎœÎŸÎ ÎŸÎ™Î—Î£Î• Î¤ÎŸ Î™Î”Î™ÎŸ conf (Ï‡Ï‰ÏÎ¯Ï‚ Î½Î­Î¿ save, Î±Ï€Î¿Ï†ÎµÏÎ³ÎµÎ¹Ï‚ duplicate)
            if (!hasBasicCols && !hasTargetCol) {
                datasetConf = baseConf;
            } else {
                // Î‘Î½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ overrides, ÎºÎ»Ï‰Î½Î¿Ï€Î¿Î¯Î·ÏƒÎµ Î³Î¹Î± Î½Î± Î¼Î·Î½ Î±Î»Î»Î¿Î¹ÏÏƒÎµÎ¹Ï‚ Ï„Î¿ Ï€Î±Î»Î¹ÏŒ
                datasetConf = new DatasetConfiguration();
                datasetConf.setDataset(baseConf.getDataset());
                datasetConf.setBasicAttributesColumns(
                        hasBasicCols ? request.getBasicCharacteristicsColumns() : baseConf.getBasicAttributesColumns());
                datasetConf.setTargetColumn(
                        hasTargetCol ? request.getTargetClassColumn() : baseConf.getTargetColumn());
                datasetConf.setUploadDate(ZonedDateTime.now());
                datasetConf = datasetConfigurationRepository.save(datasetConf);
            }

            datasetInstances = datasetService.loadTrainingInstances(datasetConf); // âœ…

        } else {
            return error("âŒ No valid dataset provided.");
        }

        // ----- Resolve AlgorithmConfiguration (Î¼Îµ Ï…Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· algorithmConfigurationId & retrain fallback)
        AlgorithmConfiguration algorithmConf;

        if (hasAlgorithmConfId) {
            algorithmConf = algorithmConfigurationRepository.findById(Integer.parseInt(request.getAlgorithmConfigurationId()))
                    .orElseThrow(() -> new EntityNotFoundException("AlgorithmConfiguration not found."));
            // Î‘Î½ Î´ÏŒÎ¸Î·ÎºÎ±Î½ options, Î¼Ï€Î¿ÏÎµÎ¯Ï‚ Î½Î± ÎµÏ€Î¹Î»Î­Î¾ÎµÎ¹Ï‚ Î½Î± Ï„Î± Î±Î³Î½Î¿Î®ÏƒÎµÎ¹Ï‚ Î® Î½Î± ÎµÏ€Î¹Ï„ÏÎ­ÏˆÎµÎ¹Ï‚ override.
            if (hasAlgorithmOpts) {
                algorithmConf = new AlgorithmConfiguration(algorithmConf.getAlgorithm());
                algorithmConf.setUser(user);
                algorithmConf.setOptions(request.getOptions());
                algorithmConf = algorithmConfigurationRepository.save(algorithmConf);
            }
        } else if (hasAlgorithmId) {
            Algorithm algorithm = algorithmRepository.findById(Integer.parseInt(request.getAlgorithmId()))
                    .orElseThrow(() -> new EntityNotFoundException("Algorithm not found."));

            algorithmConf = new AlgorithmConfiguration(algorithm);
            algorithmConf.setUser(user);
            algorithmConf.setOptions(hasAlgorithmOpts ? request.getOptions() : algorithm.getDefaultOptions());
            algorithmConf = algorithmConfigurationRepository.save(algorithmConf);

        } else if (retrainMode) {
            // âœ… Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ Î¤ÎŸ Î™Î”Î™ÎŸ algorithm configuration Î±Ï€ÏŒ Ï„Î¿ base training (Î¼Îµ Ï€ÏÎ¿Î±Î¹ÏÎµÏ„Î¹ÎºÎ¬ overrides)
            AlgorithmConfiguration baseAlgConf = retrainedFrom.getAlgorithmConfiguration();
            if (baseAlgConf == null)
                return error("âŒ Base training has no AlgorithmConfiguration.");

            if (!hasAlgorithmOpts) {
                // Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ Ï„Î¿ Î¯Î´Î¹Î¿ config (ÎºÎ±Î¸ÏŒÎ»Î¿Ï… Î½Î­Î¿ save -> Î±Ï€Î¿Ï†ÎµÏÎ³ÎµÎ¹Ï‚ duplicates)
                algorithmConf = baseAlgConf;
            } else {
                // Î‘Î½ Î­ÏƒÏ„ÎµÎ¹Î»Îµ Î½Î­Î± options, ÎºÎ»Ï‰Î½Î¿Ï€Î¿Î¯Î·ÏƒÎµ/Î´Î·Î¼Î¹Î¿ÏÏÎ³Î·ÏƒÎµ Î½Î­Î¿ Î³Î¹Î± Î½Î± ÎºÏÎ±Ï„Î®ÏƒÎµÎ¹Ï‚ Ï„Î¿ Ï€Î±Î»Î¹ÏŒ Î±Î½Î±Î»Î»Î¿Î¯Ï‰Ï„Î¿
                algorithmConf = new AlgorithmConfiguration(baseAlgConf.getAlgorithm());
                algorithmConf.setUser(user);
                algorithmConf.setOptions(request.getOptions());
                algorithmConf = algorithmConfigurationRepository.save(algorithmConf);
            }
        } else {
            return error("âŒ Algorithm information is required (algorithmId or algorithmConfigurationId).");
        }

        // ----- Î ÏÎ¿Î±Î¹ÏÎµÏ„Î¹ÎºÏŒÏ‚ ÏƒÏ…Î¼Î²Î±Ï„ÏŒÏ„Î·Ï„Î±Ï‚ Î­Î»ÎµÎ³Ï‡Î¿Ï‚ (Ï„ÏÏ€Î¿Ï‚ Î±Î»Î³Î¿ÏÎ¯Î¸Î¼Î¿Ï… vs. dataset schema)
        AlgorithmTypeEnum type = algorithmConf.getAlgorithm().getType().getName();
        if (type == AlgorithmTypeEnum.CLASSIFICATION) {
            // Ï€.Ï‡. Î­Î»ÎµÎ³Î¾Îµ ÏŒÏ„Î¹ targetColumn ÎµÎ¯Î½Î±Î¹ nominal (Î® Î¸Î± Î³Î¯Î½ÎµÎ¹ force nominal downstream ÏŒÏ€Ï‰Ï‚ Î­Ï‡ÎµÎ¹Ï‚)
        } else if (type == AlgorithmTypeEnum.REGRESSION) {
            // Ï€.Ï‡. numeric target
        } else if (type == AlgorithmTypeEnum.CLUSTERING) {
            // Ï€.Ï‡. target Î´ÎµÎ½ Î±Ï€Î±Î¹Ï„ÎµÎ¯Ï„Î±Î¹
        }

        // ----- Training
        TrainingStatus trainStatus = trainingStatusRepository.findByName(TrainingStatusEnum.REQUESTED)
                .orElseThrow(() -> new EntityNotFoundException("Training status not found."));

        Training training = new Training();
        training.setUser(user);
        training.setStatus(trainStatus);
        training.setAlgorithmConfiguration(algorithmConf);
        training.setDatasetConfiguration(datasetConf);
        training.setRetrainedFrom(retrainedFrom); // âœ… ÎºÏÎ±Ï„Î¬Î¼Îµ lineage
        training = trainingRepository.save(training);

        log.info("âœ… Training input ready: trainingId={}, datasetConfId={}, algorithmConfId={}",
                training.getId(), datasetConf.getId(), algorithmConf.getId());

        return TrainingDataInput.builder()
                .training(training)
                .datasetConfiguration(datasetConf)
                .algorithmConfiguration(algorithmConf)
                .dataset(datasetInstances)
                .build();
    }

    private TrainingDataInput error(String message) {
        log.warn(message);
        return TrainingDataInput.builder()
                .errorResponse(new GenericResponse<>(null, "", message, new Metadata()))
                .build();
    }

}
