#!/usr/bin/env python3
"""
Standardized training script that works with any user algorithm.
This file is automatically generated and should not be modified by users.
"""

import json
import pickle
import pandas as pd
import sys
import os
from pathlib import Path

def main():
    try:
        # Use environment variables or fallback to /data and /model
        data_dir = os.getenv('DATA_DIR', '/data')
        model_dir = os.getenv('MODEL_DIR', '/model')

        print(f"Using DATA_DIR: {data_dir}")
        print(f"Using MODEL_DIR: {model_dir}")

        # Load parameters
        params_path = os.path.join(data_dir, 'params.json')
        with open(params_path, 'r') as f:
            params = json.load(f)

        # Load dataset
        dataset_path = os.path.join(data_dir, 'dataset.csv')
        if not os.path.exists(dataset_path):
            raise FileNotFoundError(f"Dataset not found at {dataset_path}")

        df = pd.read_csv(dataset_path)

        # Split features and target
        # Assume last column is target, rest are features
        X = df.iloc[:, :-1].values
        y_raw = df.iloc[:, -1]

        # Convert target to numeric if it's categorical (strings)
        if y_raw.dtype == 'object' or y_raw.dtype.name == 'category':
            # Map categorical values to numeric (0, 1, 2, ...)
            y, label_mapping = pd.factorize(y_raw)
            print(f"Converted categorical target: {dict(enumerate(label_mapping))}")
        else:
            y = y_raw.values

        print(f"Dataset loaded: {X.shape[0]} samples, {X.shape[1]} features")
        print(f"Parameters: {params}")

        # Import user's algorithm
        sys.path.insert(0, data_dir)
        from algorithm import Algorithm

        # Initialize and train the algorithm
        model = Algorithm(params)
        print("Training started...")
        model.fit(X, y)
        print("Training completed!")

        # Ensure model directory exists
        os.makedirs(model_dir, exist_ok=True)

        # Save the trained model
        model_path = os.path.join(model_dir, 'trained_model.pkl')
        with open(model_path, 'wb') as f:
            pickle.dump(model, f)

        print(f"Model saved to {model_path}")

        # Save training metadata
        metadata = {
            'n_samples': int(X.shape[0]),
            'n_features': int(X.shape[1]),
            'params': params,
            'status': 'success'
        }

        metadata_path = os.path.join(model_dir, 'metadata.json')
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)

        # Save metrics file (required by the system)
        metrics = {
            'accuracy': 'N/A',  # Would need validation set to compute
            'loss': 'N/A',      # Final training loss if available
            'training_samples': int(X.shape[0]),
            'features': int(X.shape[1]),
            'epochs_completed': params.get('n_epochs', 'unknown'),
            'status': 'completed'
        }

        metrics_path = os.path.join(model_dir, 'metrics.json')
        with open(metrics_path, 'w') as f:
            json.dump(metrics, f, indent=2)

        print("Training completed successfully!")

    except Exception as e:
        print(f"Training failed: {str(e)}")
        # Save error metadata
        model_dir = os.getenv('MODEL_DIR', '/model')
        error_metadata = {
            'status': 'failed',
            'error': str(e)
        }

        os.makedirs(model_dir, exist_ok=True)
        error_path = os.path.join(model_dir, 'metadata.json')
        with open(error_path, 'w') as f:
            json.dump(error_metadata, f, indent=2)

        sys.exit(1)

if __name__ == '__main__':
    main()