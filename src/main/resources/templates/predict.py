#!/usr/bin/env python3
"""
Standardized prediction script that works with any trained model.
This file is automatically generated and should not be modified by users.
"""

import json
import pickle
import pandas as pd
import numpy as np
import sys
import os

def main():
    try:
        # Use environment variables or fallback defaults (same convention as train.py)
        data_dir = os.getenv('DATA_DIR', '/data')
        model_dir = os.getenv('MODEL_DIR', '/model')

        print(f"Using DATA_DIR: {data_dir}")
        print(f"Using MODEL_DIR: {model_dir}")

        # Load the trained model
        model_path = os.path.join(model_dir, 'trained_model.pkl')
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Trained model not found at {model_path}")

        with open(model_path, 'rb') as f:
            model = pickle.load(f)

        print("Model loaded successfully!")

        # Load test dataset
        test_data_path = os.path.join(data_dir, 'test_data.csv')
        if not os.path.exists(test_data_path):
            raise FileNotFoundError(f"Test data not found at {test_data_path}")

        df = pd.read_csv(test_data_path)

        # Extract features (assume same structure as training data)
        # If last column contains '?' or similar placeholders, assume it's a target column and drop it
        if df.iloc[:, -1].astype(str).str.contains(r'^\?$', na=False).all():
            print(f"Detected placeholder target column (last column), dropping it for prediction")
            X_test = df.iloc[:, :-1].values
        else:
            X_test = df.values
        print(f"Test data loaded: {X_test.shape[0]} samples, {X_test.shape[1]} features")

        # Make predictions
        print("Making predictions...")
        predictions = model.predict(X_test)

        # Convert to standard format
        if hasattr(predictions, 'tolist'):
            predictions = predictions.tolist()
        elif not isinstance(predictions, list):
            predictions = list(predictions)

        print(f"Generated {len(predictions)} predictions")

        # Ensure output directory exists
        os.makedirs(model_dir, exist_ok=True)

        # Save predictions to CSV in model directory (where service expects output)
        predictions_df = pd.DataFrame({
            'prediction': predictions
        })

        output_path = os.path.join(model_dir, 'predictions.csv')
        predictions_df.to_csv(output_path, index=False)

        # Save prediction metadata
        metadata = {
            'n_predictions': len(predictions),
            'status': 'success',
            'output_file': 'predictions.csv'
        }

        metadata_path = os.path.join(model_dir, 'prediction_metadata.json')
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)

        print(f"Predictions saved to {output_path}")
        print("Prediction completed successfully!")

    except Exception as e:
        print(f"Prediction failed: {str(e)}")

        model_dir = os.getenv('MODEL_DIR', '/model')

        # Save error metadata
        error_metadata = {
            'status': 'failed',
            'error': str(e)
        }

        os.makedirs(model_dir, exist_ok=True)
        error_path = os.path.join(model_dir, 'prediction_metadata.json')
        with open(error_path, 'w') as f:
            json.dump(error_metadata, f, indent=2)

        sys.exit(1)

if __name__ == '__main__':
    main()
