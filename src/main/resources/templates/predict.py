#!/usr/bin/env python3
"""
Standardized prediction script that works with any trained model.
This file is automatically generated and should not be modified by users.
"""

import json
import pickle
import pandas as pd
import numpy as np
import sys
import os

def main():
    try:
        # Use environment variables or fallback defaults (same convention as train.py)
        data_dir = os.getenv('DATA_DIR', '/data')
        model_dir = os.getenv('MODEL_DIR', '/model')

        print(f"Using DATA_DIR: {data_dir}")
        print(f"Using MODEL_DIR: {model_dir}")

        # Load the trained model
        model_path = os.path.join(model_dir, 'trained_model.pkl')
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Trained model not found at {model_path}")

        with open(model_path, 'rb') as f:
            model = pickle.load(f)

        print("Model loaded successfully!")

        # Load label mapping if it exists (for converting numeric predictions to class names)
        label_mapping = None
        label_mapping_path = os.path.join(model_dir, 'label_mapping.json')
        if os.path.exists(label_mapping_path):
            with open(label_mapping_path, 'r') as f:
                label_mapping = json.load(f)
            print(f"Label mapping loaded: {label_mapping}")

        # Load test dataset
        test_data_path = os.path.join(data_dir, 'test_data.csv')
        if not os.path.exists(test_data_path):
            raise FileNotFoundError(f"Test data not found at {test_data_path}")

        df = pd.read_csv(test_data_path)

        # Extract features (assume same structure as training data)
        # If last column contains '?' or similar placeholders, assume it's a target column and drop it
        if df.iloc[:, -1].astype(str).str.contains(r'^\?$', na=False).all():
            print(f"Detected placeholder target column (last column), dropping it for prediction")
            X_test_df = df.iloc[:, :-1]  # Keep as DataFrame for headers
            X_test = X_test_df.values
        else:
            X_test_df = df  # Keep as DataFrame for headers
            X_test = df.values
        print(f"Test data loaded: {X_test.shape[0]} samples, {X_test.shape[1]} features")

        # Make predictions
        print("Making predictions...")
        predictions = model.predict(X_test)

        # Convert to standard format
        if hasattr(predictions, 'tolist'):
            predictions = predictions.tolist()
        elif not isinstance(predictions, list):
            predictions = list(predictions)

        # Convert numeric predictions back to class names if label mapping exists
        if label_mapping is not None:
            print(f"Converting numeric predictions to class names using label mapping...")
            predictions = [label_mapping[int(pred)] if isinstance(pred, (int, np.integer, float, np.floating)) else pred
                          for pred in predictions]
            print(f"Sample predictions after conversion: {predictions[:5]}")

        print(f"Generated {len(predictions)} predictions")

        # Ensure output directory exists
        os.makedirs(model_dir, exist_ok=True)

        # Save predictions to CSV with all input features in model directory (where service expects output)
        # Create output DataFrame with original features + predictions
        output_df = X_test_df.copy()
        output_df['prediction'] = predictions

        output_path = os.path.join(model_dir, 'predictions.csv')
        output_df.to_csv(output_path, index=False)

        # Save prediction metadata
        metadata = {
            'n_predictions': len(predictions),
            'status': 'success',
            'output_file': 'predictions.csv'
        }

        metadata_path = os.path.join(model_dir, 'prediction_metadata.json')
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)

        print(f"Predictions saved to {output_path}")
        print("Prediction completed successfully!")

    except Exception as e:
        print(f"Prediction failed: {str(e)}")

        model_dir = os.getenv('MODEL_DIR', '/model')

        # Save error metadata
        error_metadata = {
            'status': 'failed',
            'error': str(e)
        }

        os.makedirs(model_dir, exist_ok=True)
        error_path = os.path.join(model_dir, 'prediction_metadata.json')
        with open(error_path, 'w') as f:
            json.dump(error_metadata, f, indent=2)

        sys.exit(1)

if __name__ == '__main__':
    main()
